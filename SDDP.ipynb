{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tutorial on SDDP\n",
    "\n",
    "\n",
    "# 1. first steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hydrothermal scheduling is the most common application of stochastic dual\n",
    "dynamic programming. To illustrate some of the basic functionality of\n",
    "`SDDP.jl`, we implement a very simple model of the hydrothermal scheduling\n",
    "problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the problem of scheduling electrical generation over three time\n",
    "periods in order to meet a known demand of 150 MWh in each period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two generators: a thermal generator, and a hydro generator. The\n",
    "thermal generator has a short-run marginal cost of \\\\\\$50/MWh in the first\n",
    "stage, \\\\\\$100/MWh in the second stage, and \\\\\\$150/MWh in the third stage.\n",
    "The hydro generator has a short-run marginal cost of \\\\\\$0/MWh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hydro generator draws water from a reservoir which has a maximum capacity\n",
    "of 200 units. We assume that at the start of the first time period, the\n",
    "reservoir is full. In addition to the ability to generate electricity by\n",
    "passing water through the hydroelectric turbine, the hydro generator can also\n",
    "spill water down a spillway (bypassing the turbine) in order to prevent the\n",
    "water from over-topping the dam. We assume that there is no cost of spillage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the optimization is to minimize the expected cost of\n",
    "generation over the three time periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Mathematical formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the problem described above and form a mathematical model. In any\n",
    "multistage stochastic programming problem, we need to identify five key\n",
    "features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The _stages_\n",
    "2. The _state_ variables\n",
    "3. The _control_ variables\n",
    "4. The _dynamics_\n",
    "5. The _stage-objective_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the description, we have three stages: `t = 1, 2, 3`. Here is a picture\n",
    "of what this looks like:\n",
    "\n",
    "![Linear policy graph](assets/deterministic_linear_policy_graph.png)\n",
    "\n",
    "Notice that the boxes form a _linear graph_. This will be important when we\n",
    "get to the code. (We'll get to more complicated graphs in future tutorials.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 State variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State variables capture the information that flows between stages. These can\n",
    "be harder to identify. However, in our model, the state variable is the volume\n",
    "of water stored in the reservoir over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model below, we're going to call the state variable `volume`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each stage `t` is an interval in time. Thus, we need to record the value of\n",
    "the state variable in each stage at two points in time: at the beginning of\n",
    "the stage, which we  refer to as the _incoming_ value of the state variable;\n",
    "and at the end of the  state, which we refer to as the _outgoing_ state\n",
    "variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to refer to the incoming value of `volume` by `volume.in` and the\n",
    "outgoing value by `volume.out`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `volume.out` when `t=1` is equal to `volume.in` when `t=2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem description also mentions some constraints on the volume of water\n",
    "in the reservoir. It cannot be negative, and the maximum level is 200 units.\n",
    "Thus, we have `0 <= volume <= 200`. Also, the description says that the\n",
    "initial value of water in the reservoir (i.e., `volume.in` when `t = 1`) is\n",
    "200 units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Control variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control variables are the actions that the agent can take during a stage to\n",
    "change the value of the state variables. (Hence the name _control_.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three control variables in our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The quantity of thermal generation, which we're going to call\n",
    "   `thermal_generation`.\n",
    "2. The quantity of hydro generation, which we're going to call\n",
    "   `hydro_generation`.\n",
    "3. The quatity of water to spill, which we're going to call `hydro_spill`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these variables are non-negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 The dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dynamics of a problem describe how the state variables evolve through time\n",
    "in response to the controls chosen by the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our problem, the state variable is the volume of water in the reservoir.\n",
    "The volume of water decreases in response to water being used for hydro\n",
    "generation and spillage. So the dynamics for our problem are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`volume.out = volume.in - hydro_generation - hydro_spill`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also put constraints on the values of the state and control variables.\n",
    "For example, in our problem, there is also a constraint that the total\n",
    "generation must meet the demand of 150 MWh in each stage. So, we have a\n",
    "constraint that:\n",
    "`hydro_generation + thermal_generation = 150`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 1.1.5 The stage-objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent's objective is to minimize the cost of generation. So in each stage,\n",
    "the agent wants to minimize the quantity of thermal generation multiplied by\n",
    "the short-run marginal cost of thermal generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In stage `t`, they want to minimize `fuel_cost[t] * thermal_generation`, where\n",
    "`fuel_cost[t]` is \\\\\\$50 when `t=1`, \\\\\\$100 when `t=2`, and \\\\\\$150 when\n",
    "`t=3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to construct a model. Since `SDDP.jl` is intended to be very\n",
    "user-friendly, we're going to give the full code first, and then walk through\n",
    "some of the details. However, you should be able to read through and\n",
    "understand most of what is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SDDP, GLPK\n",
    "\n",
    "hydro_model1 = SDDP.LinearPolicyGraph(\n",
    "    stages = 3,\n",
    "    sense = :Min,\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = with_optimizer(GLPK.Optimizer)\n",
    ") do subproblem, t\n",
    "    # Define the state variable.\n",
    "    @variable(subproblem, 0 <= volume <= 200, SDDP.State, initial_value = 200)\n",
    "    # Define the control variables.\n",
    "    @variables(subproblem, begin\n",
    "        thermal_generation >= 0\n",
    "        hydro_generation   >= 0\n",
    "        hydro_spill        >= 0\n",
    "    end)\n",
    "    # Define the constraints\n",
    "    @constraints(subproblem, begin\n",
    "        volume.out == volume.in - hydro_generation - hydro_spill\n",
    "        thermal_generation + hydro_generation == 150.0\n",
    "    end)\n",
    "    # Define the objective for each stage `t`. Note that we can use `t` as an\n",
    "    # index for t = 1, 2, 3.\n",
    "    fuel_cost = [50.0, 100.0, 150.0]\n",
    "    @stageobjective(subproblem, fuel_cost[t] * thermal_generation)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Wasn't that easy! Let's walk through some of the non-obvious features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! tip\n",
    "    For more information on `SDDP.LinearPolicyGraph`s, read\n",
    "    Create a general policy graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 What's this weird `do` syntax?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia's `do` syntax looks a little weird at first, but it's just a nice way of\n",
    "making a function that can be passed to another function. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function outer(inner::Function)\n",
    "    inner(2)\n",
    "end\n",
    "\n",
    "outer() do x\n",
    "    println(\"x^2 = \", x^2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is equivalent to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner(x) = println(\"x^2 = \", x^2)\n",
    "outer(inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in our case, we could have gone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function subproblem_builder(subproblem::JuMP.Model, t::Int)\n",
    "    # Define the state variable.\n",
    "    @variable(subproblem, 0 <= volume <= 200, SDDP.State, initial_value = 200)\n",
    "    # Define the control variables.\n",
    "    @variables(subproblem, begin\n",
    "        thermal_generation >= 0\n",
    "        hydro_generation   >= 0\n",
    "        hydro_spill        >= 0\n",
    "    end)\n",
    "    # Define the constraints\n",
    "    @constraints(subproblem, begin\n",
    "        volume.out == volume.in - hydro_generation - hydro_spill\n",
    "        thermal_generation + hydro_generation == 150.0\n",
    "    end)\n",
    "    # Define the objective for each stage `t`. Note that we can use `t` as an\n",
    "    # index for t = 1, 2, 3.\n",
    "    fuel_cost = [50.0, 100.0, 150.0]\n",
    "    @stageobjective(subproblem, fuel_cost[t] * thermal_generation)\n",
    "end\n",
    "\n",
    "hydro_model1 = SDDP.LinearPolicyGraph(\n",
    "    subproblem_builder,\n",
    "    stages = 3,\n",
    "    sense = :Min,\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = with_optimizer(GLPK.Optimizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 The keywords in the `SDDP.LinearPolicyGraph` constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully `stages` and `sense` are obvious. However, the other two are not so\n",
    "clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lower_bound`: you _must_ supply a valid bound on the objective. For our\n",
    "problem, we know that we cannot incur a negative cost so \\\\\\$0 is a valid lower\n",
    "bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`optimizer`: This is borrowed directly from JuMP's `Model` constructor:\n",
    "(`Model(with_optimizer(GLPK.Optimizer))`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Creating state variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State variables can be created like any other JuMP variables. Think of them as\n",
    "another type of variable like binary or integer. For example, to create a\n",
    "binary variable in JuMP, you go:\n",
    "```julia\n",
    "@variable(subproblem, x, Bin)\n",
    "```\n",
    "whereas to create a state variable you go\n",
    "```julia\n",
    "@variable(subproblem, x, SDDP.State)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that you have to pass a keyword argument called `initial_value` that\n",
    "gives the incoming value of the state variable in the first stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Defining the stage-objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a JuMP model, we can set the objective using `@objective`. For example:\n",
    "```julia\n",
    "@objective(subproblem, Min, fuel_cost[t] * thermal_generation)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only need to define the objective for each stage, rather than the\n",
    "whole problem, we use the `SDDP.jl`-provided `@stageobjective`.\n",
    "```julia\n",
    "@stageobjective(subproblem, fuel_cost[t] * thermal_generation)\n",
    "```\n",
    "Note that we don't have to specify the optimization sense (`Max` of `Min`)\n",
    "since this is done via the `sense` keyword argument of\n",
    "`SDDP.LinearPolicyGraph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.3 Manipulating policies \n",
    " \n",
    " ### 1.3.1 Training a policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models can be trained using the `SDDP.train` function. It accepts a\n",
    "number of keyword arguments. `iteration_limit` terminates the training after\n",
    "the provided number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDDP.train(hydro_model1; iteration_limit = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Saving the policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have finished training the policy, you can write the cuts to file\n",
    "using `SDDP.write_cuts_to_file`. You can read these cuts into a new\n",
    "model using `SDDP.read_cuts_from_file`. Note that the model must have\n",
    "the same number (and names) of the state variables, as well as the same number\n",
    "and names of the nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also save the log to a CSV file using `SDDP.write_log_to_csv`.\n",
    "This will create a CSV file with columns `iteration`, `simulation`, `bound`,\n",
    "and `time`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Simulating the policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a trained policy, you can simulate it using\n",
    "`SDDP.simulate`. The return value from `simulate` is a vector with one\n",
    "element for each replication. Each element is itself a vector, with one\n",
    "element for each stage. Each element, corresponding to a particular stage in a\n",
    "particular replication, is a dictionary that records information from the\n",
    "simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations = SDDP.simulate(\n",
    "    # The trained model to simulate.\n",
    "    hydro_model1,\n",
    "    # The number of replications.\n",
    "    1,\n",
    "    # A list of names to record the values of.\n",
    "    [:volume, :thermal_generation, :hydro_generation, :hydro_spill]\n",
    ")\n",
    "\n",
    "replication = 1\n",
    "stage = 1\n",
    "\n",
    "simulations[replication][stage]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore many of the entries for now;  they will be relevant later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " One element of iterest is `:volume`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outgoing_volume = [stage[:volume].out for stage in simulations[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Another is `:thermal_generation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermal_generation = [stage[:thermal_generation] for stage in simulations[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see the optimal policy: in the first stage, use 150 MWh of\n",
    "thermal generation and 0 MWh of hydro generation. In the second stage, use 100\n",
    "MWh of thermal and 50 MWh of hydro. In the third and final stage, use 0 MWh of\n",
    "thermal and 150 MWh of  hydro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Exercise : a hot water tank problem\n",
    "\n",
    "We consider a hot water tank for a residential building. We model the water tank as an equivalent amount of hot water at each hour $ 0 \\leq s_t \\leq 500$. We assume that it follows the dynamic\n",
    "$$ s_0 = 200, \\qquad s_{t+1} = \\rho s_t + u_t - d_t $$\n",
    "where $u_t \\leq 200$ is the amount of warmed water between $t$ and $t+1$, for a cost $c_t$ per unit, and $d_t$ the amount of extracted water. The coefficient $0<\\rho <1$ represent the heat loss.\n",
    "\n",
    "We assume that we have the following data ($t=1$ corresponds to 4am) \n",
    "\n",
    "| t     ||  1    |  2   | 3    | 4    |  5   | 6    | 7    |  8   | 9    |\n",
    "| ----  || ---   | ---  | ---  | ---  | ---  | ---  | ---  | ---  | ---  |\n",
    "| $c_t$ ||  24.3 | 28.5 | 42.5 | 50.4 | 52.6 | 51.8 | 48.9 | 48.6 | 47.04|\n",
    "| $d_t$ ||  0    | 20   | 200  | 150  | 50   | 20   | 20   | 30   | 50   |\n",
    "\n",
    "We want to define an optimal heating strategy. Hot water after $t=9$ is considered lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 1 \n",
    "\n",
    "Construct a `hw_model` representing this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ = 0.9\n",
    "c = [30 28.5 42.5 50.4 52.6 51.8 48.9 48.6 47.04]\n",
    "d = [0    20   200  150  50   20   20   30   50]\n",
    "\n",
    "hw_model1 = SDDP.LinearPolicyGraph(\n",
    "    stages = ??? , \n",
    "    sense = :Min,\n",
    "    lower_bound = ???, \n",
    "    optimizer = with_optimizer(GLPK.Optimizer)\n",
    ") do subproblem, t\n",
    "    # Define the state variable.\n",
    "    @variable(subproblem, 0 <= s <= 500, SDDP.State, initial_value = 200)\n",
    "    # Define the control variables.\n",
    "    @variables(subproblem, begin\n",
    "        ???\n",
    "    end)\n",
    "    # Define the constraints\n",
    "    @constraints(subproblem, begin\n",
    "        s.out == ???\n",
    "    end)\n",
    "    # Define the objective for each stage `t`. Note that we can use `t` as an\n",
    "    # index for t = 1, 2, 3.\n",
    "    @stageobjective(subproblem, ???)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Train and simulate the problem. Describe the optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (Optional)\n",
    "\n",
    "We are now going to consider a more contrained version of our problem, where $u \\leq 100$. \n",
    "\n",
    "#### Question 3.a )\n",
    "Is this new problem admissible ? Are we in a relatively complete recourse framework ?\n",
    "\n",
    "#### Question 3.b)\n",
    "Solving this new problem via SDDP won't work (try it !). \n",
    "By introducing a new variable solve the problem.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. adding uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now we have solved a deterministic  hydro-thermal scheduling model. We are now adding uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably missing from our previous model were inflows. Inflows are the water\n",
    "that flows into the reservoir through rainfall or rivers. These inflows are\n",
    "uncertain, and are the cause of the main trade-off in hydro-thermal\n",
    "scheduling: the desire to use water now to generate cheap electricity, against\n",
    "the risk that future inflows will be low, leading to blackouts or expensive\n",
    "thermal generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our simple hydro model, we assume that the inflows can be modelled by a discrete\n",
    "distribution with the three outcomes given in the following table:\n",
    "\n",
    "| ω    |   0 |  50 | 100 |\n",
    "| ---- | --- | --- | --- |\n",
    "| P(ω) | 1/3 | 1/3 | 1/3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the noise (the random variable) is observed by the agent at the\n",
    "start of each stage. This makes the problem a _wait-and-see_ or\n",
    "_hazard-decision_ formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent this, we can draw the following picture. The wavy lines denote\n",
    "the uncertainty arriving into the start of each stage (node).\n",
    "\n",
    "![Linear policy graph](assets/stochastic_linear_policy_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to adding this uncertainty to the model, we also need to modify\n",
    "the dynamics to include `inflow`:\n",
    "\n",
    "`volume.out = volume.in + inflow - hydro_generation - hydro_spill`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Creating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an uncertain variable to the model, we create a new JuMP variable\n",
    "`inflow`, and then call the function `SDDP.parameterize`. The\n",
    "`SDDP.parameterize` function takes three arguments: the subproblem, a\n",
    "vector of realizations, and a corresponding vector of probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_model2 = SDDP.LinearPolicyGraph(\n",
    "    stages = 3,\n",
    "    sense = :Min,\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = with_optimizer(GLPK.Optimizer)\n",
    ") do subproblem, t\n",
    "    # Define the state variable.\n",
    "    @variable(subproblem, 0 <= volume <= 200, SDDP.State, initial_value = 200)\n",
    "    # Define the control variables.\n",
    "    @variables(subproblem, begin\n",
    "        thermal_generation >= 0\n",
    "        hydro_generation   >= 0\n",
    "        hydro_spill        >= 0\n",
    "        inflow\n",
    "    end)\n",
    "    # Define the constraints\n",
    "    @constraints(subproblem, begin\n",
    "        volume.out == volume.in + inflow - hydro_generation - hydro_spill\n",
    "        demand_constraint, thermal_generation + hydro_generation == 150.0\n",
    "    end)\n",
    "    # Define the objective for each stage `t`. Note that we can use `t` as an\n",
    "    # index for t = 1, 2, 3.\n",
    "    fuel_cost = [50.0, 100.0, 150.0]\n",
    "    @stageobjective(subproblem, fuel_cost[t] * thermal_generation)\n",
    "    # Parameterize the subproblem.\n",
    "    SDDP.parameterize(subproblem, [0.0, 50.0, 100.0], [1/3, 1/3, 1/3]) do ω\n",
    "        JuMP.fix(inflow, ω)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we use the JuMP function\n",
    "[`JuMP.fix`](http://www.juliaopt.org/JuMP.jl/v0.19/variables/#JuMP.fix) to set\n",
    "the value of the `inflow` variable to `ω`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Warning :</b> `SDDP.parameterize` can only be called once in each subproblem definition!\n",
    "</div>\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Training and simulating the policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Training the policy\n",
    "\n",
    "As earlier we train the policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SDDP.train(hydro_model2; iteration_limit = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Simulating the policy\n",
    "\n",
    "We can also simulate the policy. Note that this time, the simulation is\n",
    "stochastic. One common approach to quantify the quality of the policy is to\n",
    "perform  a Monte Carlo simulation and then form a confidence interval for the\n",
    "expected cost. This confidence interval is an estimate for the upper bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the confidence interval, we can calculate the lower bound using\n",
    "`SDDP.calculate_bound`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "\n",
    "Nmc = 1000\n",
    "\n",
    "simulations = SDDP.simulate(hydro_model2, Nmc)\n",
    "\n",
    "objective_values = [\n",
    "    sum(stage[:stage_objective] for stage in sim) for sim in simulations\n",
    "]\n",
    "\n",
    "μ = round(mean(objective_values), digits = 2)\n",
    "\n",
    "ci = round(1.96 * std(objective_values) / sqrt(Nmc), digits = 2)\n",
    "\n",
    "println(\"Confidence interval: \", μ, \" ± \", ci)\n",
    "println(\"Lower bound: \", round(SDDP.calculate_bound(hydro_model2), digits = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Simulating further parameters (Optional)\n",
    "\n",
    "In addition to simulating the primal values of variables, we can also pass\n",
    "`SDDP.jl` custom recorder functions. Each of these functions takes one\n",
    "argument, the JuMP subproblem, and returns anything you can compute. For\n",
    "example, the dual of the demand constraint (which we named\n",
    "`demand_constraint`) corresponds to the price we should charge for\n",
    "electricity, since it represents the cost of each additional unit of demand.\n",
    "To calculate this, we can go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations = SDDP.simulate(\n",
    "    hydro_model2,\n",
    "    1,\n",
    "    custom_recorders = Dict{Symbol, Function}(\n",
    "        :price => (sp) -> JuMP.dual(sp[:demand_constraint])\n",
    "    )\n",
    ")\n",
    "\n",
    "prices = [stage[:price] for stage in simulations[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Exercise : Hot water with random demand\n",
    "\n",
    "The actual demand in hot water is not known in advance. We are going to consider that, for each hour, independantly of the others, the prediction have $30\\%$ chance of being $20\\%$ less than predicted, $40%$ chance of being at prediction level and$30\\%$ chance of being $20\\%$ above prediction level.\n",
    "\n",
    "In addition we are going to introduce a control $v_t$ which correspond to unmet demand, priced at $100$ per unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.\n",
    "\n",
    "Model, train and solve the problem with random demand. Simulate the obtained policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Two uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we created a\n",
    "stochastic hydro-thermal scheduling model. In this tutorial, we extend the\n",
    "problem by adding uncertainty to the fuel costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we assumed that the fuel cost was deterministic: \\\\\\$50/MWh in the\n",
    "first stage, \\\\\\$100/MWh in the second stage, and \\\\\\$150/MWh in the third\n",
    "stage. For this tutorial, we assume that in addition to these base costs, the\n",
    "actual fuel cost is correlated with the inflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new model for the uncertinty is given by the following table:\n",
    "\n",
    "| ω               |   1 |   2 |    3 |\n",
    "| ----            | --- | --- | ---- |\n",
    "| P(ω)            | 1/3 | 1/3 |  1/3 |\n",
    "| inflow          |   0 |  50 |  100 |\n",
    "| fuel_multiplier | 1.5 | 1.0 | 0.75 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In stage `t`, the objective is now to minimize:\n",
    "\n",
    "`fuel_multiplier * fuel_cost[t] * thermal_generation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Creating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an uncertain objective, we can simply call `@stageobjective`\n",
    "from inside the `SDDP.parameterize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_model3 = SDDP.LinearPolicyGraph(\n",
    "    stages = 3,\n",
    "    sense = :Min,\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = with_optimizer(GLPK.Optimizer)\n",
    ") do subproblem, t\n",
    "    # Define the state variable.\n",
    "    @variable(subproblem, 0 <= volume <= 200, SDDP.State, initial_value = 200)\n",
    "    # Define the control variables.\n",
    "    @variables(subproblem, begin\n",
    "        thermal_generation >= 0\n",
    "        hydro_generation   >= 0\n",
    "        hydro_spill        >= 0\n",
    "        inflow\n",
    "    end)\n",
    "    # Define the constraints\n",
    "    @constraints(subproblem, begin\n",
    "        volume.out == volume.in + inflow - hydro_generation - hydro_spill\n",
    "        thermal_generation + hydro_generation == 150.0\n",
    "    end)\n",
    "    fuel_cost = [50.0, 100.0, 150.0]\n",
    "    # Parameterize the subproblem.\n",
    "    Ω = [\n",
    "        (inflow = 0.0, fuel_multiplier = 1.5),\n",
    "        (inflow = 50.0, fuel_multiplier = 1.0),\n",
    "        (inflow = 100.0, fuel_multiplier = 0.75)\n",
    "    ]\n",
    "    SDDP.parameterize(subproblem, Ω, [1/3, 1/3, 1/3]) do ω\n",
    "        JuMP.fix(inflow, ω.inflow)\n",
    "        @stageobjective(subproblem,\n",
    "            ω.fuel_multiplier * fuel_cost[t] * thermal_generation\n",
    "        )\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training and simulating the policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous two tutorials, we train and simulate the policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDDP.train(hydro_model3; iteration_limit = 10)\n",
    "\n",
    "\n",
    "Nmc = 1000\n",
    "simulations = SDDP.simulate(hydro_model3, Nmc,\n",
    "[:volume, :thermal_generation, :hydro_generation, :hydro_spill])\n",
    "\n",
    "objective_values = [\n",
    "    sum(stage[:stage_objective] for stage in sim) for sim in simulations\n",
    "]\n",
    "\n",
    "using Statistics\n",
    "\n",
    "μ = round(mean(objective_values), digits = 2)\n",
    "ci = round(1.96 * std(objective_values) / sqrt(Nmc), digits = 2)\n",
    "\n",
    "println(\"Confidence interval: \", μ, \" ± \", ci)\n",
    "println(\"Lower bound: \", round(SDDP.calculate_bound(hydro_model3), digits = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous setions, we formulated, solved, and simulated multistage\n",
    "stochastic optimization problems. However, we haven't really investigated what\n",
    "the solution looks like. Luckily, `SDDP.jl` includes a number of plotting\n",
    "tools to help us do that. In this tutorial, we explain the tools and make some\n",
    "pretty pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two plot types help visualize the policy. Thus, we simulate some trajectories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmc = 1000\n",
    "simulations = SDDP.simulate(hydro_model3, Nmc, \n",
    "    [:volume, :thermal_generation, :hydro_generation, :hydro_spill]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have some data in `simulations` to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Spaghetti plots (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plotting utility we discuss is a _spaghetti_ plot (you'll understand\n",
    "the name when you see the graph)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a spaghetti plot, begin by creating a new\n",
    "`SDDP.SpaghettiPlot` instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = SDDP.SpaghettiPlot(simulations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add plots to `plt` using the `SDDP.add_spaghetti` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDDP.add_spaghetti(plt; title = \"Reservoir volume\") do data\n",
    "    return data[:volume].out\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't have just return values from the simulation, you can compute things\n",
    "too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDDP.add_spaghetti(\n",
    "    plt; title = \"Fuel cost\", ymin = 0, ymax = 250\n",
    ") do data\n",
    "    if data[:thermal_generation] > 0\n",
    "        return data[:stage_objective] / data[:thermal_generation]\n",
    "    else  # No thermal generation, so return 0.0.\n",
    "        return 0.0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are many keyword arguments in addition to `title`. For\n",
    "example, we fixed the minimum and maximum values of the y-axis using `ymin`\n",
    "and `ymax`. See the `SDDP.add_spaghetti` documentation for all the\n",
    "arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having built the plot, we now need to display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDDP.save(plt, \"spaghetti_plot.html\", open = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should open a webpage that looks like [this\n",
    "one](../assets/spaghetti_plot.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the mouse, you can highlight individual trajectories by hovering over\n",
    "them. This makes it possible to visualize a single trajectory across multiple\n",
    "dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you click on the plot, then trajectories that are close to the mouse\n",
    "pointer are shown darker and those further away are shown lighter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Publication plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the interactive Javascript plots, you can also create some\n",
    "publication ready plots using the `SDDP.publication_plot` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info :</b> You need to install the `Plots.jl` \n",
    "    package for this to work. We used the `GR` backend (`gr()`), but any\n",
    "    `Plots.jl` backend should work.\n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SDDP.publication_plot` implements a plot recipe to create ribbon\n",
    "plots of each variable against the stages. The first argument is the vector of\n",
    "simulation dictionaries and the second argument is the dictionary key that you\n",
    "want to plot. Standard `Plots.jl` keyword arguments such as `title` and `xlabel`\n",
    "can be used to modify the look of each plot. By default, the plot displays\n",
    "ribbons of the 0-100, 10-90, and 25-75 percentiles. The dark, solid line in the\n",
    "middle is the median (i.e. 50'th percentile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using Plots\n",
    "plot(\n",
    "    SDDP.publication_plot(simulations, title = \"Outgoing volume\") do data\n",
    "        return data[:volume].out\n",
    "    end,\n",
    "    SDDP.publication_plot(simulations, title = \"Thermal generation\") do data\n",
    "        return data[:thermal_generation]\n",
    "    end,\n",
    "    xlabel = \"Stage\",\n",
    "    ylims = (0, 200),\n",
    "    layout = (1, 2),\n",
    "    margin_bottom = 5,\n",
    "    size = (1000, 300)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should open a plot window with a plot that looks like:\n",
    "\n",
    "![publication plot](assets/publication_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save this plot as a PDF using the `Plots.jl` function `savefig`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(\"my_picture.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Exercise\n",
    "\n",
    "Plot water stock, heating control and unserved demand for the hot-water tank problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
